<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Dishani Lahiri</title>

  <meta name="author" content="Dishani Lahiri">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
<table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
<tr style="padding:0px">
  <td style="padding:0px">
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:2.5%;width:63%;vertical-align:middle">
        <p class="name" style="text-align: center;">
          Dishani Lahiri
        </p>
        <p>I am a 2nd year MS in Computer Vision student <a href = "https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">
          (MSCV)</a> in the Robotics Institute
          at Carnegie Mellon University. I work on computer vision, natural language processing
          and machine learning.
        </p>
        <p>
          At CMU, I specifically work with <a href="https://arxiv.org/abs/2309.01252">3D reconstruction, scene understanding</a>, and
          <a href="https://dishanil.github.io/HDIL/">fine-tuning large language models</a> for personalized domain-specific usecases.
          I am currently advised by <a href="https://kriskitani.github.io/">Prof. Kris Kitani</a> to build a low-power visual-inertial odometry system for
          <a href="https://www.projectaria.com/">Aria AR glasses</a> that can be used reliably in unseen environments as well.
        </p>
        <p>
          During my summer internship at <a href="https://www.slingshot.xyz/">Slingshot AI</a>, I got a chance to work in a
          very fast-paced environment with high code-quality standards which enriched my research, software engineering, and product skills.
          I worked on optimizing fine-tuning of personalized text-to-image models (you can see my results on the home page) , improving the results for Generative aging models, and
          fine-tuning <a href="https://huggingface.co/meta-llama/Llama-2-7b-hf">LLaMA2-7B</a> for personalized text style transfer (paper coming soon).
        </p>
        <p>
          I developed an interest in diffusion models and currently aim to work on text-to-video models.
        </p>
        <p>
          Previously I worked on impactful and profitable projects at <a href="https://research.samsung.com/sri-b">
          Samsung R&D Institute, Bangalore
        </a>. At Samsung, I was a key innovator for the development and deployment of <a href="https://www.samsung.com/us/support/answer/ANS00086006/">
          AI Night mode
        </a> in Samsung Flagship series and the <a href="https://www.samsung.com/levant/support/mobile-devices/professional-photography-with-galaxy-expert-raw-app/">
          Expert RAW application.
        </a>
        </p>
        <p>
          I completed my undergraduate studies in ECE from <a href="http://www.dtu.ac.in/">DTU</a> in 2019.
          My Bachelor's thesis on Neural Caption Generator was advised by <a href="https://scholar.google.com/citations?hl=en&user=an1urc0AAAAJ&view_op=list_works&sortby=pubdate">
          Prof. S. Indu
        </a>, ex-Head of Department, ECE, DTU. Owing to my interest in human activity recognition, I also worked with
          <a href="https://scholar.google.co.in/citations?user=TUsEwA8AAAAJ&hl=en">Prof. D.K. Vishwakarma</a>.
        </p>
        <p style="text-align:center">
          <a href="mailto:dishanil">Email</a> &nbsp;/&nbsp;
          <a href="data/Dishani_Lahiri_Resume.pdf">CV</a> &nbsp;/&nbsp;
          <a href="data/DishaniLahiri-bio.txt">Bio</a> &nbsp;/&nbsp;
          <a href="https://scholar.google.com/citations?user=a6z0RWoAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
          <a href="https://www.linkedin.com/in/dishani-lahiri/">LinkedIn</a> &nbsp;/&nbsp;
          <a href="https://github.com/dishanil">Github</a>
        </p>
      </td>
      <td style="padding:2.5%;width:40%;max-width:40%">
        <a href="images/Dishani_image.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Dishani_circle_image.png" class="hoverZoomLink"></a>
      </td>
    </tr>
    </tbody></table>

    <table width="100%" align="center" style="margin-left:10px" cellspacing="0" cellpadding="0" border="0">
      <tr>
        <td width="16.6%" valign="top" align="center">
          <img src="images/cmu_ri.jpeg" alt="sym" width="105%"></a>
          <!-- <p style="line-height:1.3; font-size:12pt">CMU<br>M.S. in Computer Vision<br>Jan. 21 - June. 22</p> -->
          <p style="line-height:1.3;"><a href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-computer-vision/">CMU</a><br>MS in Computer Vision<br>Aug. 22 - Dec. 23</p>
        </td>

        <td width="16.6%" valign="top" align="center">
          <img src="images/slingshot.jpeg" alt="sym" width="95%"></a>
          <p style="line-height:1.3;"><a href="https://www.slingshot.xyz/">Slingshot AI</a><br>ML Research Intern<br>May 23 - Aug. 23</p>
        </td>

        <td width="16.6%" valign="top" align="center">
          <img src="images/srib.jpeg" alt="sym" width="62%"></a>
          <p style="line-height:1.3;"><a href="https://research.samsung.com/sri-b">Samsung R&D Institute</a><br>Senior CV Engineer<br>June 19 - July 22<br>Software Engineer Intern<br>May 18 - July 18</p>
        </td>


        <td width="16.6%" valign="top" align="center">
          <img src="images/dtu.jpeg" alt="sym" width="83%"></a>
          <p style="line-height:1.3;"><a href="http://www.dtu.ac.in/">DTU, Delhi</a><br>
            B.Tech. ECE<br>
            Aug. 15 - May 19</p>
        </td>
      </tr>
    </table>

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <h2>Projects & Publications</h2>
        <p>
          I'm interested in computer vision, natural language processing, and machine learning, especially in building
          personalized multi-modal solutions for edge devices.
        </p>
      </td>
    </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ddp_image'>
            <img src='images/s2rf.png' style="margin-top: 0px;" width="200"></div>
          <img src='images/s2rf.png' style="margin-top: 0px;" width="200">
        </div>
        <script type="text/javascript">
          function ddp_start() {
            document.getElementById('ddp_image').style.opacity = "1";
          }

          function ddp_stop() {
            document.getElementById('ddp_image').style.opacity = "0";
          }
          ddp_stop()
        </script>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2309.01252">
          <papertitle>S2RF: Semantically Stylized Radiance Fields</papertitle>
        </a>
        <br>
        <strong>Dishani Lahiri*</strong>,
        <a href="https://www.linkedin.com/in/neeraj-panse-782b53155/">Neeraj Panse*</a>,
        <a href="https://www.linkedin.com/in/moneishkumar/">Moneish Kumar*</a>
        <br>
        <em>ICCV</em>, 2023 Workshop on AI for 3D Content Creation
        <br>
        <a href="https://arxiv.org/abs/2309.01252">paper</a> |
        <a href="https://github.com/neepacmu/ARF-svox2">code</a> |
        <a href="https://dishanil.github.io/S2RF/">webpage</a>

        <p></p>
        <p>
          We present our method for transferring style from any arbitrary image(s) to object(s) within a 3D scene.
          Our primary objective is to offer more control in 3D scene stylization, facilitating the creation of
          customizable and stylized scene images from arbitrary viewpoints. To achieve this, we propose a
          novel approach that incorporates nearest neighborhood-based loss, allowing for flexible 3D scene
          reconstruction while effectively capturing intricate style details and ensuring multi-view consistency.
        </p>
      </td>
    </tr>

    <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
      <td style="padding:20px;width:30%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ddp_image'>
            <img src='images/abha.png' style="margin-top: 0px;" width="200"></div>
          <img src='images/abha.png' style="margin-top: 0px;" width="200">
        </div>
        <script type="text/javascript">
          function ddp_start() {
            document.getElementById('ddp_image').style.opacity = "1";
          }

          function ddp_stop() {
            document.getElementById('ddp_image').style.opacity = "0";
          }
          ddp_stop()
        </script>
      </td>
      <td style="padding:20px;width:70%;vertical-align:middle">
        <a href="https://ieeexplore.ieee.org/document/8340622">
          <papertitle>S2RF: Semantically Stylized Radiance Fields</papertitle>
        </a>
        <br>
        <strong>Dishani Lahiri*</strong>,
        <a href="https://ieeexplore.ieee.org/author/37086370532">Chhavi Dhiman</a>,
        <a href="https://ieeexplore.ieee.org/author/37061549900">Dinesh Kumar Vishwakarma</a>
        <br>
        <em>IEEE</em>, 2017 Conference on Information and Communication Technology (CICT)
        <br>
        <a href="https://ieeexplore.ieee.org/document/8340622">paper</a>

        <p></p>
        <p>
          We propose a solution to detect abnormal human actions in the image using Histogram of Oriented Gradients (HoG) as the feature descriptor,
          Principal Component Analysis (PCA) as the dimensionality-reduction technique, and Support Vector Machine as the ML tool for classification.
          We also release a dataset for abnormal human activities of fainting, headache, and chest pain.
        </p>
      </td>
    </tr>
    </table>

    <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td>
          <heading>Teaching Experience</heading>
          <ul>
            <li> <b>Advanced Computer Vision, CMU (TA)</b> | Instructor: <a href="https://davheld.github.io/">Prof. David Held</a> | Fall 2023 <br>
              This is a new <b>PhD-level</b> course wherein I am involved in preparing and improving the assignments, maintaining
              the course website, holding Office Hours, and helping students with the theory and code of concepts covered throughout the course.
            </li>

            <li> <b>Machine Learning, CMU (TA)</b> | Instructor: <a href="https://www.cs.cmu.edu/~mgormley/">Prof. Matt Gormley</a> | Spring 2023 <br>
              Preparing and suggesting exam and assignment problems, and material in order to make the course more effective. Holding recitations and office hours for students.
            </li>
          </ul>
        </td>
      </tr>
    </table>

    <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td>
          <heading>Awards and Recognition</heading>
          <ul>
            <li> <b>Winner (most creative use of Github), <a href="https://www.acmatcmu.com/hackcmu/">HackCMU</a></b> :
              Awarded for our project, <a href="https://dishanil.github.io/HDIL/">How Do I Look?</a> using image-to-text and Large Language Models to generate suggestions for attires based on the event
            </li>

            <li> <b>Samsung Excellence Award (earlier Samsung Citizen Award), Advanced Development Category</b> :
              Company-wide Award to recognize major contributions towards the R&D in Night Mode for S21 Flagship series
            </li>

            <li> <b>Standout Performer in Advanced R&D Work</b> :
              Succeeded in being 1 out of 100 people in Camera Systems Group to receive this award for constant exceptional efforts towards research and implementation
            </li>

            <li> <b>Samsung Citizen Award, Group Excellence Category</b> :
              Company-wide Group award to recognize major contributions towards the development of camera usecases in A71-5G device, the first device with SM7250 chipset
            </li>

            <li> <b>Standout Performer in Advanced R&D Work</b> :
              Succeeded in being 1 out of 100 people in Camera Systems Group to receive this award for constant exceptional efforts towards research and implementation
            </li>

            <li> <b>1H-2020 Project Incentives</b> :
              Succeeded in being 1 in 2 out of 100 people in Camera Systems Group to receive the incentive in lieu of exceptional performance in critical projects
            </li>

            <li> <b>Appreciation letter from HRD Ministry of India</b> :
              For being in top 0.1 percentile scorers in 12th class CBSE examination. HRD Ministry is the Government of India Body formulates the National Policy of Education
            </li>
          </ul>
        </td>
      </tr>
    </table>

</body>
</html>